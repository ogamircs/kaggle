ones = sum(data$REAL)
if(ones == 0 || ones == n) return(1)
truePos = tp0 = ones
accum = tn = 0
thershold = data$PRED[1]
for(i in 1:n) {
if(data$PRED[i] != thershold) {
thershold = data$PRED[i]
accum = accum + tn*(truePos + tp0)
tp0 = truePos
tn = 0
}
tn = tn + 1 - data$ACTUAL[i]
truePos = truePos - data$ACTUAL[i]
}
accum = accum +  tn * (truePos + tp0)
AUC = accum / (2 * ones * (n-ones))
AUC
accum
library(dplyr)
install.packages("dplyr")
data <- read.csv(file="~/Downloads/auc_test.csv",sep=",")
library(dplyr)
arrange(data,PRED)
data <- arrange(data,PRED)
View(data)
source('~/Downloads/AUC.R')
AUC
data <- read.csv(file="~/Downloads/auc_test.csv",sep=",")
library(dplyr)
data <- arrange(data,PRED)
n = nrow(data)
#for(i in 1:n) {
#}
ones = sum(data$REAL)
if(ones == 0 || ones == n) return(1)
truePos = tp0 = ones
accum = tn = 0
thershold = data$PRED[1]
for(i in 1:n) {
if(data$PRED[i] != thershold) {
thershold = data$PRED[i]
accum = accum + tn*(truePos + tp0)
tp0 = truePos
tn = 0
}
tn = tn + 1 - data$ACTUAL[i]
truePos = truePos - data$ACTUAL[i]
}
debugSource('~/Downloads/AUC.R')
truePos
data <- read.csv(file="~/Downloads/auc_test.csv",sep=",")
library(dplyr)
data <- arrange(data,PRED)
n = nrow(data)
#for(i in 1:n) {
#}
ones = sum(data$REAL)
if(ones == 0 || ones == n) return(1)
truePos = tp0 = ones
accum = tn = 0
thershold = data$PRED[1]
for(i in 1:n) {
if(data$PRED[i] != thershold) {
thershold = data$PRED[i]
accum = accum + tn*(truePos + tp0)
tp0 = truePos
tn = 0
}
tn = tn + 1 - data$ACTUAL[i]
truePos = truePos - data$ACTUAL[i]
}
debugSource('~/Downloads/AUC.R')
debugSource('~/Downloads/AUC.R')
source('~/Downloads/AUC.R')
source('~/Downloads/AUC.R')
source('~/.active-rstudio-document')
install.packages(c("quantspec", "randomForestSRC"))
install.packages("KFAS")
install.packages("breastCancerNKI")
install.packages("Biobase")
source('~/Downloads/CPPinR.R')
install.packages("microbenchmark")
source('~/Downloads/CPPinR.R')
install.packages("Rcpp")
source('~/Downloads/CPPinR.R')
source('~/Downloads/CPPinR.R')
source('~/Downloads/CPPinR.R')
source('~/Downloads/CPPinR.R')
source('~/Downloads/CPPinR.R')
install.packages(c("gss", "klaR"))
install.packages(c("mice", "tm"))
install.packages("pROC")
install.packages("Matrix")
install.packages("ploty")
install.packages("plotly")
install.packages("devtools")
library("devtools")
install_github("ropensci/plotly")
library(plotly)
py <- plotly()
set_credentials_file(username="amircs", api_key="qvjt1ohqzi")
py <- plotly()
ggiris <- qplot(Petal.Width, Sepal.Length, data = iris, color = Species)
r <- py$ggplotly(ggiris)
r$response$url
install_github("predcomps", user = "dchudz")
library(devtools)  # first install devtools if you haven't
install_github("predcomps", user = "dchudz")
n <- 200
x1 <- runif(n = n, min = 0, max = 1)
x2 <- runif(n = n, min = 0, max = 1)
x3 <- runif(n = n, min = 0, max = 10)
y <- 2 * x1 + (-2) * x2 + 1 * x3
df <- data.frame(x1, x2, x3, y)
fittedLm <- lm(y ~ ., data = df)
library(predcomps)
apcDF <- GetPredCompsDF(fittedLm, df = df)
PlotPredCompsDF(apcDF) + theme_gray(base_size = 18)
install.packages(c("arules", "pmml", "pmmlTransformations"))
install.packages(c("gplots", "lpSolve"))
library(Biobase)
install.packages("Biobase")
install.packages("Biobase",type="source")
source("http://bioconductor.org/biocLite.R")
biocLite("Biobase")
library(Biobase)
data(nki)
exprs(nki)[1:5,1:5]
data(nki)
browseVignettes()
library(dynpred)
data(nki)
exprs(nki)[1:5,1:5]
head(pData(nki))
library(dynpred)
featureNames(nki)[1:20]
View(nki)
library(dynpred)
data(nki)
library(rattle)
rattle()
install.packages("playwith",type="source")
install.packages("rggobi",type="source")
install.packages("ggobi",type="source")
install.packages("ggobi")
citation(dynpred)
library(dynpred)
citation(dynpred)
citation(nki)
citation(data)
citation()
install.packages("ggvis")
library(ggvis)
data(iris)
ggvis()
??ggvis
ggvis(iris)
View(iris)
ggvis(iris, x = ~Sepal.Length, y = ~Sepal.Width)
ggvis(iris, x = ~Sepal.Length, y = ~Sepal.Width) %>%
layer_points()
mtcars %>% ggvis(~mpg, ~wt, fill := "red")
mtcars %>% ggvis(~mpg, ~wt) %>% layer_points()
mtcars %>%
ggvis(~mpg, ~wt) %>%
layer_points() %>%
layer_smooths()
iris %>%
ggvis(~Sepal.Length, ~Petal.Length) %>%
layer_points() %>%
layer_smooths()
ls -la
ls
library(maptools)
library(maps)
library(rgeos)
library(ggcounty)
install.packages("maptools")
install.packages("rgeos")
install.packages("ggcounty")
library(maptools)
library(maps)
library(rgeos)
install.packages("rgeos")
install.packages("rgeos",type="source")
install.packages("~/Downloads/RGeostats_10.0.1_macosx.tgz", repos = NULL)
library(rgeos)
library(RGeostats)
install.packages("~/Downloads/rgeos_0.3-5.tgz", repos = NULL)
library(rgeos)
install_github("hrbrmstr/ggcounty")
library(devtools)
install_github("hrbrmstr/ggcounty")
library(ggcounty)
maine <- ggcounty("Maine")
maine$gg
library(maptools)
library(maps)
library(rgeos)
library(ggcounty)
# you can grab ggcounty via:
# install.packages("devtools")
# install_github("hrbrmstr/ggcounty")
# grab the US map with counties
us <- ggcounty.us(color="#777777", size=0.125)
# plot the points in "Xfinity red" with a
# reasonable alpha setting & point size
gg <- us$gg
gg <- gg %+% xfin + aes(x=longitude, y=latitude)
gg <- gg + geom_point(color="#c90318", size=1, alpha=1/20)
gg <- gg + coord_map(projection="mercator")
gg <- gg + xlim(range(us$map$long))
gg <- gg + ylim(range(us$map$lat))
gg <- gg + labs(x="", y="")
gg <- gg + theme_bw()
# the map tends to stand out beter on a non-white background
# but the panel background color isn't truly "necessary"
gg <- gg + theme(panel.background=element_rect(fill="#878787"))
gg <- gg + theme(panel.grid=element_blank())
gg <- gg + theme(panel.border=element_blank())
gg <- gg + theme(axis.ticks.x=element_blank())
gg <- gg + theme(axis.ticks.y=element_blank())
gg <- gg + theme(axis.text.x=element_blank())
gg <- gg + theme(axis.text.y=element_blank())
gg <- gg + theme(legend.position="none")
gg
install.packages("mapproj")
library(ggcounty)
maine <- ggcounty("Maine")
maine$gg
source('~/Downloads/country_plots.R')
library(maptools)
library(maps)
library(rgeos)
library(ggcounty)
# you can grab ggcounty via:
# install.packages("devtools")
# install_github("hrbrmstr/ggcounty")
# grab the US map with counties
us <- ggcounty.us(color="#777777", size=0.125)
# plot the points in "Xfinity red" with a
# reasonable alpha setting & point size
gg <- us$gg
gg <- gg %+% xfin + aes(x=longitude, y=latitude)
gg <- gg + geom_point(color="#c90318", size=1, alpha=1/20)
gg <- gg + coord_map(projection="mercator")
gg <- gg + xlim(range(us$map$long))
gg <- gg + ylim(range(us$map$lat))
gg <- gg + labs(x="", y="")
gg <- gg + theme_bw()
# the map tends to stand out beter on a non-white background
# but the panel background color isn't truly "necessary"
gg <- gg + theme(panel.background=element_rect(fill="#878787"))
gg <- gg + theme(panel.grid=element_blank())
gg <- gg + theme(panel.border=element_blank())
gg <- gg + theme(axis.ticks.x=element_blank())
gg <- gg + theme(axis.ticks.y=element_blank())
gg <- gg + theme(axis.text.x=element_blank())
gg <- gg + theme(axis.text.y=element_blank())
gg <- gg + theme(legend.position="none")
gg
library(ggcounty)
# built-in US population by FIPS code data set
data(population)
# define appropriate (& nicely labeled) population breaks
population$brk <- cut(population$count,
breaks=c(0, 100, 1000, 10000, 100000, 1000000, 10000000),
labels=c("0-99", "100-1K", "1K-10K", "10K-100K",
"100K-1M", "1M-10M"),
include.lowest=TRUE)
# get the US counties map (lower 48)
us <- ggcounty.us()
# start the plot with our base map
gg <- us$g
# add a new geom with our population (choropleth)
gg <- gg + geom_map(data=population, map=us$map,
aes(map_id=FIPS, fill=brk),
color="white", size=0.125)
# define nice colors
gg <- gg + scale_fill_manual(values=c("#ffffcc", "#c7e9b4", "#7fcdbb",
"#41b6c4", "#2c7fb8", "#253494"),
name="Population")
# plot the map
gg
library(maptools)
library(maps)
library(rgeos)
library(ggcounty)
ca <- ggcounty.ca()
ca <- ggcounty.canada()
install.packages(c("Cairo", "deSolve", "ggvis", "igraph", "matlab", "mgcv", "randomForestSRC", "rwt"))
library(maps)
library(mapsdata)
install.packages("mapdata")
install.packages("maptools")
install.packages("scales")
library(maps)
library(mapdata)
library(maptools)  #for shapefiles
library(scales)  #for transparency
pcontorta <- readShapePoly("pinucont.shp")   #layer of data for species range
samps <- read.csv("FieldSamples.csv")   #my data for sampling sites, contains a column of "lat" and a column of "lon" with GPS points in decimal degrees
map("worldHires","Canada", xlim=c(-140,-110),ylim=c(48,64), col="gray90", fill=TRUE)  #plot the region of Canada I want
map("worldHires","usa", xlim=c(-140,-110),ylim=c(48,64), col="gray95", fill=TRUE, add=TRUE)  #add the adjacent parts of the US; can't forget my homeland
plot(pcontorta, add=TRUE, xlim=c(-140,-110),ylim=c(48,64), col=alpha("darkgreen", 0.6), border=FALSE)  #plot the species range
points(samps$lon, samps$lat, pch=19, col="red", cex=0.5)  #plot my sample sites
install.packages("mapproj")
library(mapproj)
map(database= "world", ylim=c(45,90), xlim=c(-160,-50), col="grey80", fill=TRUE, projection="gilbert", orientation= c(90,0,225))
lon <- c(-72, -66, -107, -154)  #fake longitude vector
lat <- c(81.7, 64.6, 68.3, 60)  #fake latitude vector
coord <- mapproject(lon, lat, proj="gilbert", orientation=c(90, 0, 225))  #convert points to projected lat/long
points(coord, pch=20, cex=1.2, col="red")  #plot converted points
library(maps)
library(mapdata)
map("worldHires","Canada”, xlim=c(-141,-53), ylim=c(40,85), col="gray90”, fill=TRUE)
library(maps)
library(mapdata)
map("worldHires","Canada", xlim=c(-141,-53), ylim=c(40,85), col="gray90", fill=TRUE)
map("worldHires","Canada", fill=TRUE)
library(psych)
source('~/Downloads/consumer_understading.R')
install.packages("NMF")
library(psych)
set.seed(6112014)
offline<-sim.rasch(nvar=30, n=200, mu=-0.5, sd=0,
d=c(2,2,2,3,3,3,4,4,4,4,0,0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3))
online<-sim.rasch(nvar=30, n=200,  mu=-0.5, sd=0,
d=c(0,0,0,1,1,1,2,2,2,2,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,4,4,4,4))
tp<-rbind(offline$items,
online$items)
tp<-data.frame(tp)
names(tp)<-c("Search engine",
"Price comparison",
"Website",
"Hint from Expert",
"User forum",
"Banner or Pop-up",
"Newsletter",
"E-mail request",
"Guidebook",
"Checklist",
"Packaging information",
"PoS promotion",
"Recommendation friends",
"Show window",
"Information at counter",
"Advertising entrance",
"Editorial newspaper",
"Consumer magazine",
"Ad in magazine",
"Flyer",
"Personal advice",
"Sampling",
"Information screen",
"Information display",
"Customer magazine",
"Poster",
"Voucher",
"Catalog loyalty program",
"Offer loyalty card",
"Service hotline")
rows<-apply(tp,1,sum)
table(rows)
cols<-apply(tp,2,sum)
cols
fill<-sum(tp)/(400*30)
fill
segment<-c(rep(1,200),rep(2,200))
segment
seg_profile<-t(aggregate(tp, by=list(segment), FUN=mean))
plot(c(1,30),c(min(seg_profile[2:30,]),
max(seg_profile[2:30,])), type="n",
xlab="Touchpoints (First 10 Online/Last 20 Offline)",
ylab="Proportion Experiencing Touchpoint")
lines(seg_profile[2:30,1], col="blue", lwd=2.5)
lines(seg_profile[2:30,2], col="red", lwd=2.5)
legend('topright',
c("Offline","Online"), lty=c(1,1),
lwd=c(2.5,2.5), col=c("blue","red"))
tp_cluster<-kmeans(tp[rows>0,], 2, nstart=25)
tp_cluster$center
table(segment[rows>0],tp_cluster$cluster)
library(NMF)
fit<-nmf(tp[rows>0,], 2, "frobenius")
fit
summary(fit)
W<-basis(fit)
round(W*10000,0)
W2<-max.col(W)
table(segment[rows>0],W2)
H<-coef(fit)
round(t(H),2)
basismap(fit,Rowv=NA)
ls()
install.packages("geometry")
toBibtex(citation("geometry"))
install.packages(c("arfima", "Ecdat", "FeedbackTS", "gplots", "lgarch", "lme4", "mgcv", "mvtnorm", "network", "party", "pomp", "rgl", "spd", "stochvol", "subplex", "verification"))
install.packages("ape")
install.packages("Formula")
q()
install.packages("tm")
install.packages(c("ape", "randomForestSRC", "SparseM"))
install.packages("mvcwt")
install.packages(c("class", "gss", "gWidgets", "gWidgetstcltk", "jsonlite", "mgcv", "pdfetch", "randomForest", "rattle", "sandwich"))
install.packages(c("arules", "GeneNet", "lpSolve", "markdown", "mime", "MSBVAR", "RandomFields", "RCurl", "RItools", "RJSONIO", "shiny", "stsm.class"))
install.packages("pwr")
library(pwr)
library(glmnet)
data(iris)
View(iris)
iris_predictors_matrix = as.matrix(iris[,c(1,2,3,4)])
View(iris_predictors_matrix)
iris_target = as.matrix(iris[,5])
glm <- glmnet(x=iris_predictors_matrix,y=as.factor(iris_target),alpha=1)
iris_predictors_matrix = as.matrix(iris[,c(1,2,3)])
iris_target = as.matrix(iris[,4])
glm <- glmnet(x=iris_predictors_matrix,y=as.factor(iris_target),alpha=1)
glm <- glmnet(x=iris_predictors_matrix,y=iris_target,alpha=1)
print(glm)
plot(glm)
best_lambda <- glm$lambda.min
glm$lambda
min(glm$lambda)
scores <- predict(glm,iris_predictors_matrix)
View(scores)
scores <- predict(glm, s=best_lambda,iris_predictors_matrix)
View(scores)
scores <- predict(glm, s=best_lambda,iris_predictors_matrix,type="response")
View(scores)
library(glmnet)
data(iris)
#Everything in matrix should be double with no nulls
iris_predictors_matrix = as.matrix(iris[,c(1,2,3)])
iris_target = as.matrix(iris[,4])
#train
glm <- glmnet(x=iris_predictors_matrix,y=iris_target,alpha=1)
#analyse
plot(glm)
best_lambda <- min(glm$lambda)
#score
#say for now we are scoring the same data
scores <- predict(glm, s=best_lambda,iris_predictors_matrix,type="response")
View(scores)
error = mean(scores - iris_target)
print(error)
mean_abs_error = mean( abs(scores - iris_target) / iris_target)
print(mean_abs_error)
library(glmnet)
data(iris)
#Everything in matrix should be double with no nulls
iris_predictors_matrix = as.matrix(iris[,c(1,2,3)])
iris_target = as.matrix(iris[,4])
#train
glm <- glmnet(x=iris_predictors_matrix,y=iris_target,alpha=1)
#analyse
plot(glm)
best_lambda <- min(glm$lambda)
glm$beta
plot(glm$lambda)
library(glmnet)
data(iris)
#Everything in matrix should be double with no nulls
iris_predictors_matrix = as.matrix(iris[,c(1,2,3)])
iris_target = as.matrix(iris[,4])
#train
glm <- glmnet(x=iris_predictors_matrix,y=iris_target,alpha=1)
#analyse
plot(glm)
plot(glm$lambda)
best_lambda <- min(glm$lambda)
glm$a0
glm$nobs
data = c("monday", "tuesday", "wednesday")
var_name = "variable1"
eval(parse( paste("var_name <-",data,collapse="") ))
eval(parse( paste(var_name," <- data", collapse="") ))
eval( paste(var_name," <- data", collapse="") )
variable1
eval( parse( text = paste(var_name," <- data", collapse="") ) )
install.packages("bigrf")
install.packages(c("arm", "deldir", "descr", "glarma", "hexbin", "jsonlite", "klaR", "lgtdl", "LPStimeSeries", "nloptr", "optmatch", "pbkrtest", "pdfetch", "pomp", "portes", "psych", "RandomFields", "rje", "sem", "SnowballC", "survey", "tiger", "timsac", "vcd", "xlsx"))
install.packages(c("bigmemory.sri", "car", "httr", "NLP", "semPlot", "survey"))
install.packages(c("arules", "HSAUR", "party"))
install.packages(c("codetools", "MASS"))
install.packages("xlsxjars")
install.packages(c("labeling", "NLP", "season"))
setwd("~/Kaggle/Forest Cover Type Prediction")
train = read.csv("train.csv")
head(train)
i = 1
s1 = ((i-1)*n+1) #start of the subset
s2 = (i*n) #end of the subset
subset = s1:s2
cv.train = train[-subset,] #90% of data - everything minus the subset
cv.test = train[subset,] #10% of data - everything in the subset
write.csv(cv.train,"DL_train.csv", sep=",", row.names=FALSE)
write.csv(cv.test,"DL_test.csv", sep=",", row.names=FALSE)
setwd("~/Kaggle/Forest Cover Type Prediction")
train = read.csv("train.csv")
head(train)
k = 10
n = floor(nrow(train)/k) #size of each fold
i = 1
s1 = ((i-1)*n+1) #start of the subset
s2 = (i*n) #end of the subset
subset = s1:s2
cv.train = train[-subset,] #90% of data - everything minus the subset
cv.test = train[subset,] #10% of data - everything in the subset
write.csv(cv.train,"DL_train.csv", sep=",", row.names=FALSE)
write.csv(cv.test,"DL_test.csv", sep=",", row.names=FALSE)
